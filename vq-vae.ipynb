{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple, Any\n",
        "\n",
        "import chex\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "# jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ad8384-c1c6-4c81-d20a-80e660961aed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "86920ea9-dc68-4af5-a584-45058d9964fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "WaGPnFqLUxFa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset pipline"
      ],
      "metadata": {
        "id": "ukGZuNfiXSkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train, x_test = ((x_train / 127.5) - 1), ((x_test / 127.5) -1)\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "def create_dataset():\n",
        "  # Create a TensorFlow data pipeline for the training set\n",
        "  train_dataset = (\n",
        "      tf.data.Dataset\n",
        "      .from_tensor_slices((x_train, y_train))\n",
        "      .repeat()\n",
        "      .shuffle(buffer_size=5000)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "      .as_numpy_iterator())\n",
        "\n",
        "  # Create a TensorFlow data pipeline for the test set.\n",
        "  test_dataset = (\n",
        "      tf.data.Dataset\n",
        "      .from_tensor_slices((x_test, y_test))\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "      .as_numpy_iterator())\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "def get_batch(dataset):\n",
        "  images, labels = next(dataset)\n",
        "\n",
        "  images, labels = jnp.array(images), jnp.array(labels)\n",
        "  # images = jnp.reshape(images, (BATCH_SIZE, -1)) # flatten the images\n",
        "  return images, labels\n",
        "\n",
        "train_dataset, test_dataset = create_dataset()"
      ],
      "metadata": {
        "id": "6SZi0CVi9hbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c657c81a-e057-44c9-d103-652bb0d8a6a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test get_batch"
      ],
      "metadata": {
        "id": "COmCti08XaWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_labels = get_batch(train_dataset)\n",
        "test_images.shape, test_labels.shape"
      ],
      "metadata": {
        "id": "7cgyLqLk_bKc",
        "outputId": "5ee96500-acc1-46e3-cf18-159607e84268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 28, 28), (16, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "rUpckDyi4aKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    num_embeddings: int = 3\n",
        "    embedding_dim: int = 2\n",
        "    beta: float = 0.2\n",
        "\n",
        "    def setup(self):\n",
        "        self.pre_quant_conv = nn.Conv(features=2, kernel_size=(1,), padding='SAME')\n",
        "        self.embedding = nn.Embed(num_embeddings=self.num_embeddings, features=self.embedding_dim)\n",
        "        self.post_quant_conv = nn.Conv(features=4, kernel_size=(1,), padding='SAME')\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, training: bool = True):\n",
        "        # Encoder\n",
        "        x = nn.Conv(features=16, kernel_size=(4,), strides=(2,), padding='SAME')(x)\n",
        "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Conv(features=4, kernel_size=(4,), strides=(2,), padding='SAME')(x)\n",
        "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
        "        encoded_output = nn.relu(x)\n",
        "\n",
        "        quant_input = self.pre_quant_conv(encoded_output)\n",
        "\n",
        "        ## Quantization\n",
        "        B, H, W, C = quant_input.shape\n",
        "        quant_input = quant_input.reshape((B, H * W, C))\n",
        "\n",
        "        # Compute pairwise distances and find index of nearest embedding\n",
        "        min_encoding_indices = self._dist_batch(quant_input, self.embedding.embedding)\n",
        "\n",
        "        # Select the embedding weights\n",
        "        quant_out = self.embedding(min_encoding_indices)\n",
        "\n",
        "        # Compute losses\n",
        "        commitment_loss = jnp.mean((quant_out - quant_input)**2)\n",
        "        codebook_loss = jnp.mean((quant_out - jax.lax.stop_gradient(quant_input))**2)\n",
        "        quantize_losses = codebook_loss + self.beta * commitment_loss\n",
        "\n",
        "        # Ensure straight through gradient\n",
        "        quant_out = quant_input + jax.lax.stop_gradient(quant_out - quant_input)\n",
        "\n",
        "        # Reshaping back to original input shape\n",
        "        quant_out = quant_out.reshape((B, H, W, C))\n",
        "\n",
        "        ## Decoder part\n",
        "        decoder_input = self.post_quant_conv(quant_out)\n",
        "        x = nn.ConvTranspose(features=16, kernel_size=(4,), strides=(2,), padding='SAME')(decoder_input)\n",
        "        x = nn.BatchNorm(use_running_average=not training)(x)\n",
        "        x = nn.relu(x)\n",
        "        output = nn.ConvTranspose(features=1, kernel_size=(4,), strides=(2,), padding='SAME')(x)\n",
        "        output = nn.tanh(output)\n",
        "\n",
        "        return output, quantize_losses\n",
        "\n",
        "    def _dist(self, quant_input_single_row, embedding_table):\n",
        "      distances = jnp.sum((quant_input_single_row - embedding_table)**2, axis=-1)\n",
        "      min_index = jnp.argmin(distances)\n",
        "      return min_index\n",
        "\n",
        "    def _dist_batch(self, quant_input_batch, embedding_table):\n",
        "      quant_input_fn = jax.vmap(self._dist, in_axes=(0, None), out_axes=(0))\n",
        "      quant_input_batch_fn = jax.vmap(quant_input_fn, in_axes=(0, None), out_axes=(0))\n",
        "      return quant_input_batch_fn(quant_input_batch, embedding_table)\n"
      ],
      "metadata": {
        "id": "n1Ur2p7wMYWk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainState(train_state.TrainState):\n",
        "  key: jax.random.KeyArray\n",
        "  batch_stats: Any\n",
        "\n",
        "random_key = jax.random.PRNGKey(99)\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "\n",
        "model = Autoencoder()\n",
        "\n",
        "test_image, test_label = test_images[0], test_labels[0]\n",
        "test_image = test_image[jnp.newaxis, :, :, jnp.newaxis] # B, H, W, C\n",
        "(output, quantize_losses), params = model.init_with_output(jrand.PRNGKey(99), test_image, training=True)\n",
        "batch_stats = params[\"batch_stats\"]\n",
        "params = params[\"params\"]"
      ],
      "metadata": {
        "id": "3QM-Xtp1ZOcI",
        "outputId": "2265fd65-6c43-443d-e2bc-d34ead58686b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-1afeb5a7edd2>:2: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
            "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
            "  key: jax.random.KeyArray\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_apply(params, batch_stats, inputs, training):\n",
        "  return model.apply({\"params\": params, \"batch_stats\": batch_stats}, inputs, training=training)\n",
        "\n",
        "model_apply_batch = jax.vmap(model_apply, in_axes=(None, None, 0, None), out_axes=(0))\n",
        "\n",
        "def forward_pass(params, batch_stats, state, batch):\n",
        "  inputs, _ = batch # you are using reconstruction loss, so NO need of targets.\n",
        "  reconstructed, new_batch_stats, = state.apply_fn(\n",
        "      params,\n",
        "      batch_stats,\n",
        "      inputs,\n",
        "      True, # training\n",
        "      mutable=['batch_stats'],\n",
        "    )\n",
        "\n",
        "  PER_HOST_BATCH_SIZE = BATCH_SIZE // jax.device_count()\n",
        "\n",
        "  reconstructed = jnp.reshape(reconstructed, (PER_HOST_BATCH_SIZE, -1)) # flatten the reconstructed to (32, 784)\n",
        "\n",
        "  chex.assert_shape(inputs, (PER_HOST_BATCH_SIZE, 784))\n",
        "  chex.assert_shape(reconstructed, (PER_HOST_BATCH_SIZE, 784))\n",
        "\n",
        "  loss = (inputs - reconstructed) ** 2\n",
        "  loss = loss.mean()\n",
        "  return loss, new_batch_stats\n",
        "\n",
        "def train_step(state, inputs, targets):\n",
        "  batch = inputs, targets\n",
        "  grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "  params = state.params\n",
        "  (loss, new_batch_stats), grads = grad_fn(state.params, state.batch_stats, state, batch)\n",
        "\n",
        "  loss = jax.lax.pmean(loss, axis_name=\"devices\")\n",
        "  grads = jax.lax.pmean(grads, axis_name=\"devices\")\n",
        "\n",
        "  state = state.apply_gradients(grads=grads, batch_stats=new_batch_stats)\n",
        "  return state, loss\n",
        "\n",
        "opt = optax.adam(learning_rate=0.001)\n",
        "state = TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt, key=random_key, batch_stats=batch_stats)"
      ],
      "metadata": {
        "id": "7e9M7_uLZ1VR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pmap the train_step.\n",
        "train_step_pmap = jax.pmap(train_step, in_axes=(0, 0, 0), out_axes=(0), axis_name=\"devices\")"
      ],
      "metadata": {
        "id": "KO7mMUbMuXNl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replicate state\n",
        "states = jax.device_put_replicated(state, jax.local_devices())"
      ],
      "metadata": {
        "id": "BaQTgEWzvfC6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "steps_per_epoch = len(x_train) // BATCH_SIZE\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"epoch: \", epoch)\n",
        "    train_dataset, _ = create_dataset()\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        inputs, targets = get_batch(train_dataset)\n",
        "\n",
        "        # create device dimension for minibatch\n",
        "        inputs = inputs.reshape((jax.device_count(), -1, 28, 28, 1))\n",
        "        targets = targets.reshape((jax.device_count(), -1, 10))\n",
        "\n",
        "        states, loss = train_step_pmap(states, inputs, targets)\n",
        "        print(\"loss\", loss[0]) if step%100==0 else None"
      ],
      "metadata": {
        "id": "2I7eEBn3P6Iy",
        "outputId": "12b924f8-9258-4e38-d0f9-31036c444e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "vmap was requested to map its argument along axis 0, which implies that its rank should be at least 1, but is only 0 (its shape is ())",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_get_axis_size\u001b[0;34m(name, shape, axis)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-06820777a910>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_pmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2ac1fe7ecd21>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(state, inputs, targets)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# differentiate wrt 0th pos argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_batch_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"devices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2ac1fe7ecd21>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(params, batch_stats, state, batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;31m# you are using reconstruction loss, so NO need of targets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   reconstructed, new_batch_stats, = state.apply_fn(\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mbatch_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_get_axis_size\u001b[0;34m(name, shape, axis)\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmin_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0;31m# TODO(mattjj): better error message here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   1283\u001b[0m           \u001b[0;34mf\"{name} was requested to map its argument along axis {axis}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m           \u001b[0;34mf\"which implies that its rank should be at least {min_rank}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: vmap was requested to map its argument along axis 0, which implies that its rank should be at least 1, but is only 0 (its shape is ())"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = jax.tree_map(lambda x: x[0], states)"
      ],
      "metadata": {
        "id": "qjy-ePiARvUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_reconstructions(model, params, batch, n=10):\n",
        "    inputs, _ = batch\n",
        "    reconstructed = state.apply_fn(params, inputs, False)\n",
        "    fig, axes = plt.subplots(2, n, figsize=(n * 2, 4))\n",
        "    for i in range(n):\n",
        "        axes[0, i].imshow(inputs[i].reshape(28, 28), cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "        axes[1, i].imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
        "        axes[1, i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some reconstructionsmodel_apply_batch\n",
        "train_dataset, test_dataset = create_dataset()\n",
        "plot_reconstructions(model, state.params, get_batch(test_dataset))\n"
      ],
      "metadata": {
        "id": "Lhn0oaJPcL8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}