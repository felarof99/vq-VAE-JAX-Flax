{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import chex\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()\n",
        "jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ad8384-c1c6-4c81-d20a-80e660961aed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "e48fb561-7cc6-4e83-c7a9-6ce49c1a6c3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 512"
      ],
      "metadata": {
        "id": "WaGPnFqLUxFa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset pipline"
      ],
      "metadata": {
        "id": "ukGZuNfiXSkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train, x_test = ((x_train / 127.5) - 1), ((x_test / 127.5) -1)\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "def create_dataset():\n",
        "  # Create a TensorFlow data pipeline for the training set\n",
        "  train_dataset = (\n",
        "      tf.data.Dataset\n",
        "      .from_tensor_slices((x_train, y_train))\n",
        "      .repeat()\n",
        "      .shuffle(buffer_size=5000)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "      .as_numpy_iterator())\n",
        "\n",
        "  # Create a TensorFlow data pipeline for the test set.\n",
        "  test_dataset = (\n",
        "      tf.data.Dataset\n",
        "      .from_tensor_slices((x_test, y_test))\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "      .as_numpy_iterator())\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "def get_batch(dataset):\n",
        "  images, labels = next(dataset)\n",
        "\n",
        "  images, labels = jnp.array(images), jnp.array(labels)\n",
        "  # images = jnp.reshape(images, (BATCH_SIZE, -1)) # flatten the images\n",
        "  return images, labels\n",
        "\n",
        "train_dataset, test_dataset = create_dataset()"
      ],
      "metadata": {
        "id": "6SZi0CVi9hbf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test get_batch"
      ],
      "metadata": {
        "id": "COmCti08XaWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_labels = get_batch(train_dataset)\n",
        "test_images.shape, test_labels.shape"
      ],
      "metadata": {
        "id": "7cgyLqLk_bKc",
        "outputId": "69f0f083-4e67-4413-98da-5546a6194cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((512, 28, 28), (512, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "rUpckDyi4aKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    num_embeddings: int = 3\n",
        "    embedding_dim: int = 2\n",
        "    beta: float = 0.2\n",
        "\n",
        "    def setup(self):\n",
        "        self.pre_quant_conv = nn.Conv(features=2, kernel_size=(1,), padding='SAME')\n",
        "        self.embedding = nn.Embed(num_embeddings=self.num_embeddings, features=self.embedding_dim)\n",
        "        self.post_quant_conv = nn.Conv(features=4, kernel_size=(1,), padding='SAME')\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, training: bool = True):\n",
        "        # Encoder\n",
        "        x = nn.Conv(features=16, kernel_size=(4,), strides=(2,), padding='SAME')(x)\n",
        "        x = nn.BatchNorm(use_running_average=True)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Conv(features=4, kernel_size=(4,), strides=(2,), padding='SAME')(x)\n",
        "        x = nn.BatchNorm(use_running_average=True)(x)\n",
        "        encoded_output = nn.relu(x)\n",
        "\n",
        "        quant_input = self.pre_quant_conv(encoded_output)\n",
        "\n",
        "        ## Quantization\n",
        "        B, H, W, C = quant_input.shape\n",
        "        quant_input = quant_input.reshape((B, H * W, C))\n",
        "\n",
        "        # Compute pairwise distances and find index of nearest embedding\n",
        "        min_encoding_indices = self._dist_batch(quant_input, self.embedding.embedding)\n",
        "\n",
        "        # Select the embedding weights\n",
        "        quant_out = self.embedding(min_encoding_indices)\n",
        "\n",
        "        # Compute losses\n",
        "        commitment_loss = jnp.mean((quant_out - quant_input)**2)\n",
        "        codebook_loss = jnp.mean((quant_out - jax.lax.stop_gradient(quant_input))**2)\n",
        "        quantize_losses = codebook_loss + self.beta * commitment_loss\n",
        "\n",
        "        # Ensure straight through gradient\n",
        "        quant_out = quant_input + jax.lax.stop_gradient(quant_out - quant_input)\n",
        "\n",
        "        # Reshaping back to original input shape\n",
        "        quant_out = quant_out.reshape((B, H, W, C))\n",
        "\n",
        "        ## Decoder part\n",
        "        decoder_input = self.post_quant_conv(quant_out)\n",
        "        x = nn.ConvTranspose(features=16, kernel_size=(4,), strides=(2,), padding='SAME')(decoder_input)\n",
        "        x = nn.BatchNorm(use_running_average=True)(x)\n",
        "        x = nn.relu(x)\n",
        "        output = nn.ConvTranspose(features=1, kernel_size=(4,), strides=(2,), padding='SAME')(x)\n",
        "        output = nn.tanh(output)\n",
        "\n",
        "        return output, quantize_losses\n",
        "\n",
        "    def _dist(self, quant_input_single_row, embedding_table):\n",
        "      distances = jnp.sum((quant_input_single_row - embedding_table)**2, axis=-1)\n",
        "      min_index = jnp.argmin(distances)\n",
        "      return min_index\n",
        "\n",
        "    def _dist_batch(self, quant_input_batch, embedding_table):\n",
        "      quant_input_fn = jax.vmap(self._dist, in_axes=(0, None), out_axes=(0))\n",
        "      quant_input_batch_fn = jax.vmap(quant_input_fn, in_axes=(0, None), out_axes=(0))\n",
        "      return quant_input_batch_fn(quant_input_batch, embedding_table)\n"
      ],
      "metadata": {
        "id": "n1Ur2p7wMYWk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainState(train_state.TrainState):\n",
        "  key: jax.random.KeyArray\n",
        "\n",
        "random_key = jax.random.PRNGKey(99)\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "\n",
        "model = Autoencoder()\n",
        "\n",
        "test_image, test_label = test_images[0], test_labels[0]\n",
        "test_image = test_image[jnp.newaxis, :, :, jnp.newaxis] # B, H, W, C\n",
        "(output, quantize_losses), params = model.init_with_output(jrand.PRNGKey(99), test_image, training=False)\n",
        "params = params[\"params\"]"
      ],
      "metadata": {
        "id": "3QM-Xtp1ZOcI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_apply(params, inputs, training):\n",
        "  return model.apply({\"params\": params}, inputs, training=training)\n",
        "\n",
        "model_apply_batch = jax.vmap(model_apply, in_axes=(None, 0, None), out_axes=(0))\n",
        "\n",
        "def forward_pass(params, state, batch):\n",
        "  inputs, _ = batch # you are using reconstruction loss, so NO need of targets.\n",
        "  reconstructed = state.apply_fn(\n",
        "      params,\n",
        "      inputs,\n",
        "      True # training\n",
        "    )\n",
        "\n",
        "  PER_HOST_BATCH_SIZE = BATCH_SIZE // jax.device_count()\n",
        "\n",
        "  reconstructed = jnp.reshape(reconstructed, (PER_HOST_BATCH_SIZE, -1)) # flatten the reconstructed to (32, 784)\n",
        "\n",
        "  chex.assert_shape(inputs, (PER_HOST_BATCH_SIZE, 784))\n",
        "  chex.assert_shape(reconstructed, (PER_HOST_BATCH_SIZE, 784))\n",
        "\n",
        "  loss = (inputs - reconstructed) ** 2\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "def train_step(state, inputs, targets):\n",
        "  batch = inputs, targets\n",
        "  grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "  params = state.params\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "\n",
        "  loss = jax.lax.pmean(loss, axis_name=\"devices\")\n",
        "  grads = jax.lax.pmean(grads, axis_name=\"devices\")\n",
        "\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state, loss\n",
        "\n",
        "opt = optax.adam(learning_rate=0.001)\n",
        "state = TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt, key=random_key)"
      ],
      "metadata": {
        "id": "7e9M7_uLZ1VR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pmap the train_step.\n",
        "train_step_pmap = jax.pmap(train_step, in_axes=(0, 0, 0), out_axes=(0), axis_name=\"devices\")"
      ],
      "metadata": {
        "id": "KO7mMUbMuXNl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replicate state\n",
        "states = jax.device_put_replicated(state, jax.local_devices())"
      ],
      "metadata": {
        "id": "BaQTgEWzvfC6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets.shape"
      ],
      "metadata": {
        "id": "1SnddAV6lJGd",
        "outputId": "55822eb7-bf0f-49e9-ae1b-a1aed2c55799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "steps_per_epoch = len(x_train) // BATCH_SIZE\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"epoch: \", epoch)\n",
        "    train_dataset, _ = create_dataset()\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        inputs, targets = get_batch(train_dataset)\n",
        "\n",
        "        # create device dimension for minibatch\n",
        "        inputs = inputs.reshape((jax.device_count(), -1, 28, 28, 1))\n",
        "        targets = targets.reshape((jax.device_count(), -1, 10))\n",
        "\n",
        "        states, loss = train_step_pmap(states, inputs, targets)\n",
        "        print(\"loss\", loss[0]) if step%100==0 else None"
      ],
      "metadata": {
        "id": "2I7eEBn3P6Iy",
        "outputId": "40c0d026-fcb0-4969-e51e-c7364dfef33e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ScopeCollectionNotFound",
          "evalue": "Tried to access \"mean\" from collection \"batch_stats\" in \"/BatchNorm_0\" but the collection is empty. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeCollectionNotFound)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mScopeCollectionNotFound\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-06820777a910>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_pmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-82e8f61c6363>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(state, inputs, targets)\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# differentiate wrt 0th pos argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"devices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-82e8f61c6363>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(params, state, batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;31m# you are using reconstruction loss, so NO need of targets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   reconstructed = state.apply_fn(\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-82e8f61c6363>\u001b[0m in \u001b[0;36mmodel_apply\u001b[0;34m(params, inputs, training)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_apply_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6f204fc0e6bf>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_running_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/linen/normalization.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, use_running_average)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mfeature_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_axes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     ra_mean = self.variable('batch_stats', 'mean',\n\u001b[0m\u001b[1;32m    249\u001b[0m                             \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             feature_shape)\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(self, col, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mutable_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_collection_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopeCollectionNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopeVariableNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m       \u001b[0minit_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mScopeCollectionNotFound\u001b[0m: Tried to access \"mean\" from collection \"batch_stats\" in \"/BatchNorm_0\" but the collection is empty. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeCollectionNotFound)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = jax.tree_map(lambda x: x[0], states)"
      ],
      "metadata": {
        "id": "qjy-ePiARvUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_reconstructions(model, params, batch, n=10):\n",
        "    inputs, _ = batch\n",
        "    reconstructed = state.apply_fn(params, inputs, False)\n",
        "    fig, axes = plt.subplots(2, n, figsize=(n * 2, 4))\n",
        "    for i in range(n):\n",
        "        axes[0, i].imshow(inputs[i].reshape(28, 28), cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "        axes[1, i].imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
        "        axes[1, i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some reconstructionsmodel_apply_batch\n",
        "train_dataset, test_dataset = create_dataset()\n",
        "plot_reconstructions(model, state.params, get_batch(test_dataset))\n"
      ],
      "metadata": {
        "id": "Lhn0oaJPcL8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}