{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import chex\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "# jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "866b47f0-4654-4578-f27d-9ca40325e931",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset pipline"
      ],
      "metadata": {
        "id": "ukGZuNfiXSkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Create a TensorFlow data pipeline for the training set\n",
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_train, y_train))\n",
        "    .shuffle(buffer_size=5000)\n",
        "    .batch(64)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "    .as_numpy_iterator())\n",
        "\n",
        "# Create a TensorFlow data pipeline for the test set.\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_test, y_test))\n",
        "    .batch(64)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "    .as_numpy_iterator())\n",
        "\n",
        "def get_batch(training: bool = True):\n",
        "  images, labels = (\n",
        "      next(train_dataset) if training\n",
        "      else next(test_dataset))\n",
        "\n",
        "  images, labels = jnp.array(images), jnp.array(labels)\n",
        "  return images, labels"
      ],
      "metadata": {
        "id": "6SZi0CVi9hbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e6596d6-c9e7-4cde-c236-5fede32a5de8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test get_batch"
      ],
      "metadata": {
        "id": "COmCti08XaWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_labels = get_batch()\n",
        "test_images.shape, test_labels.shape"
      ],
      "metadata": {
        "id": "7cgyLqLk_bKc",
        "outputId": "336715c6-450b-46bf-bfe9-d81b5623bde9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 32, 32, 3), (64, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "rUpckDyi4aKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(nn.Module):\n",
        "  \"\"\"Takes an image and creates patches.\"\"\"\n",
        "  patch_size: int\n",
        "  embed_dim: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.conv = nn.Conv(\n",
        "        features=self.embed_dim,\n",
        "        kernel_size=(self.patch_size, self.patch_size),\n",
        "        strides=(self.patch_size, self.patch_size),\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "  def __call__(self, images):\n",
        "    patches = self.conv(images)\n",
        "    h, w, c = patches.shape\n",
        "    patches = jnp.reshape(patches, (h*w, c))\n",
        "    return patches"
      ],
      "metadata": {
        "id": "QnpE69HHzvPb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(nn.Module):\n",
        "  hidden_dim: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    # x should be a single example\n",
        "    chex.assert_rank(x, 2)\n",
        "    T, C = x.shape\n",
        "\n",
        "    # project to hidden dim\n",
        "    x = nn.Dense(self.hidden_dim)(x)\n",
        "\n",
        "    # add cls token\n",
        "    cls = self.param('cls_token', nn.initializers.zeros, (1, self.hidden_dim))\n",
        "    x = jnp.concatenate([cls, x], axis=0)\n",
        "\n",
        "    # we added an extra cl token at the beginning\n",
        "    T = T + 1\n",
        "\n",
        "    # Add position embedding\n",
        "    pos_embed = self.param(\n",
        "        'position_embedding',\n",
        "        nn.initializers.normal(stddev=0.02), # From BERT\n",
        "        (T, self.hidden_dim)\n",
        "    )\n",
        "    return x + pos_embed"
      ],
      "metadata": {
        "id": "4KY7-Fj15LU2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test patches"
      ],
      "metadata": {
        "id": "ox2MYKFR4UuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image, test_label = test_images[0], test_labels[0]\n",
        "test_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBoE30Yd1x7E",
        "outputId": "ffbe0bbb-765e-4d88-8a85-9fadeedce9ea"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = Patches(patch_size=4, embed_dim=192)\n",
        "output, params = p.init_with_output(jax.random.PRNGKey(99), test_image)\n",
        "params = params[\"params\"]"
      ],
      "metadata": {
        "id": "YP2idan-2MRl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = PatchEncoder(hidden_dim=256)\n",
        "output_pe, params = pe.init_with_output(jax.random.PRNGKey(999), output)\n",
        "params = params[\"params\"]"
      ],
      "metadata": {
        "id": "yDS23aq9OFp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling contd."
      ],
      "metadata": {
        "id": "mwM2QsJl4gwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  output_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    # **new**: attention paper uses 4 times token_info_size when doing linear transformation.\n",
        "    # and then projects it back to token_info_size in linear transformation layer.\n",
        "    self.ffwd = nn.Dense(features=4 * self.output_size)\n",
        "\n",
        "    # **new**: projection layer, which goes back into residual pathway.\n",
        "    self.projection = nn.Dense(self.output_size)\n",
        "\n",
        "  def __call__(self, x, training: bool):\n",
        "    x = nn.relu(self.ffwd(x))\n",
        "    x = self.projection(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "  token_info_size: int # head_size; how much (emb dim) info each token emits for keys, queries, values.\n",
        "  T: int # block size; number of tokens in a block\n",
        "\n",
        "  def setup(self):\n",
        "    # key, query will take vector of size C.\n",
        "    # i.e., channels containing info of token and will output token_info_size\n",
        "    self.key_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.query_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "    self.value_layer = nn.Dense(self.token_info_size, use_bias=False)\n",
        "\n",
        "    self.dropout = nn.Dropout(rate=0.2)\n",
        "\n",
        "\n",
        "  def __call__(self, block_of_tokens_with_info_channels: jnp.array, training: bool):\n",
        "    \"\"\"Accepts a block of tokens with info channels, like (8, 65).\"\"\"\n",
        "\n",
        "    # TODO(ntnsonti): Double check; but tril should not be learnable according cGPT.\n",
        "    tril = jnp.tril(jnp.ones(shape=(self.T, self.T)))\n",
        "\n",
        "    # input: (T, info channels )\n",
        "    # output: (T, token_info_size)\n",
        "    keys = self.key_layer(block_of_tokens_with_info_channels)\n",
        "    queries = self.query_layer(block_of_tokens_with_info_channels)\n",
        "    values = self.value_layer(block_of_tokens_with_info_channels)\n",
        "\n",
        "    # chanel info size\n",
        "    C = int(block_of_tokens_with_info_channels.shape[-1])\n",
        "    # print(\"[ntn99] channel_info_size: \", C)\n",
        "\n",
        "    # compute attention score.\n",
        "    wei = jnp.dot(queries, keys.T) * C**0.5 # (T, token_info_size) * (token_info_size, T) == (T, T)\n",
        "    wei = jnp.where(tril==0, -jnp.inf, wei)\n",
        "    wei = nn.softmax(wei, axis=-1)\n",
        "\n",
        "    attention_values = jnp.dot(wei, values) # (T, T) * (T, token_info_size))\n",
        "\n",
        "    attention_values = self.dropout(attention_values, deterministic=not training)\n",
        "\n",
        "    return attention_values # (T, token_info_size)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  num_heads: int\n",
        "  final_token_info_size: int # After concatenating from all heads, how much info (values -- emb size) you have on each token.\n",
        "  T: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.token_info_size_per_head = int(self.final_token_info_size/self.num_heads)\n",
        "    self.heads = [\n",
        "        Head(token_info_size=self.token_info_size_per_head, T=self.T) for _ in range(self.num_heads)\n",
        "    ]\n",
        "\n",
        "    self.projection = nn.Dense(features=self.final_token_info_size)\n",
        "\n",
        "    self.dropout = nn.Dropout(rate=0.2)\n",
        "\n",
        "  def __call__(self, block_of_tokens_with_info_channels: jnp.array, training: bool):\n",
        "    out_from_each_head = jnp.array([h(block_of_tokens_with_info_channels, training) for h in self.heads])\n",
        "\n",
        "    # You just run multiple attention heads in parallel and concatenate\n",
        "    # their output along channel dimension, i.e., dim==-1\n",
        "    out_from_all_heads = jnp.concatenate(out_from_each_head, axis=-1)\n",
        "    # print(\"[ntn99] out_from_all_heads concatenated shape: \", out_from_all_heads.shape)\n",
        "\n",
        "    projection =  self.projection(out_from_all_heads)\n",
        "\n",
        "    return self.dropout(projection, deterministic=not training)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "  num_heads: int\n",
        "  final_token_info_size: int\n",
        "  T: int\n",
        "\n",
        "  def setup(self):\n",
        "    # communication.\n",
        "    self.self_attention_heads = MultiHeadAttention(num_heads=self.num_heads,\n",
        "                                                   final_token_info_size=self.final_token_info_size,\n",
        "                                                   T=self.T)\n",
        "\n",
        "    # computation.\n",
        "    self.computation_layer = FeedForward(output_size=self.final_token_info_size)\n",
        "\n",
        "    self.ln1 = nn.LayerNorm()\n",
        "    self.ln2 = nn.LayerNorm()\n",
        "\n",
        "    self.dropout = nn.Dropout(rate=0.2)\n",
        "\n",
        "  def __call__(self, x, training: bool):\n",
        "    x = x + self.self_attention_heads(self.ln1(x), training)\n",
        "    # print(\"[ntn99] input size after attention_head: \", x.shape)\n",
        "\n",
        "    x = x + self.computation_layer(self.ln2(x), training)\n",
        "    # print(\"[ntn99] input size after computation (end of block): \", x.shape)\n",
        "\n",
        "    x = self.dropout(x, deterministic=not training)\n",
        "    return x"
      ],
      "metadata": {
        "id": "UUzSsxUPB5DK"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "  patch_size: int\n",
        "  embed_dim: int\n",
        "  hidden_dim: int\n",
        "  n_heads: int\n",
        "  drop_p: float\n",
        "  num_layers: int\n",
        "  mlp_dim: int\n",
        "  num_classes: int\n",
        "  T: int = 4 # +1 cls token\n",
        "\n",
        "  def setup(self):\n",
        "    self.patch_extracter = Patches(self.patch_size, self.embed_dim)\n",
        "    self.patch_encoder = PatchEncoder(self.hidden_dim)\n",
        "    self.dropout = nn.Dropout(self.drop_p)\n",
        "    self.blocks = [\n",
        "        Block(num_heads=4, final_token_info_size=self.embed_dim, T=(self.T+1)) for _ in range(self.num_layers)]\n",
        "\n",
        "    self.cls_head = nn.Dense(features=self.num_classes)\n",
        "\n",
        "  def __call__(self, x, training: bool = True):\n",
        "    x = self.patch_extracter(x)\n",
        "    x = self.patch_encoder(x)\n",
        "    x = self.dropout(x, deterministic=not training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.blocks[i](x, training)\n",
        "\n",
        "    # MLP head\n",
        "    x = x[:, 0] # [CLS] token\n",
        "    x = self.cls_head(x)\n",
        "    return x\n",
        ""
      ],
      "metadata": {
        "id": "imNRmHUAZR4B"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainState(train_state.TrainState):\n",
        "  key: jax.random.KeyArray\n",
        "\n",
        "\n",
        "random_key = jax.random.PRNGKey(99)\n",
        "random_key, random_subkey = jax.random.split(random_key)\n",
        "\n",
        "model = ViT(patch_size=16, embed_dim=192, hidden_dim=192,\n",
        "    n_heads=3, drop_p=0.1, num_layers=12, mlp_dim=768, num_classes=10, T=4)\n",
        "\n",
        "\n",
        "output, params = model.init_with_output(jrand.PRNGKey(99), test_image, training=False)\n",
        "params = params[\"params\"]\n"
      ],
      "metadata": {
        "id": "3QM-Xtp1ZOcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e96c5b1-90fc-48dc-d61d-1cfb3b2ebc18"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-98d0cb874b68>:2: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
            "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
            "  key: jax.random.KeyArray\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_apply(params, inputs):\n",
        "  dropout_key = jax.random.PRNGKey(0) # TODO need to fix this.\n",
        "  return model.apply({\"params\": params}, inputs, False, rngs={'dropout': dropout_key})\n",
        "\n",
        "model_apply_batch = jax.vmap(model_apply, in_axes=(None, 0), out_axes=(0))\n",
        "\n",
        "def forward_pass(params, state, batch):\n",
        "  inputs, targets = batch\n",
        "  logits = state.apply_fn(params, inputs)\n",
        "  loss = optax.softmax_cross_entropy(logits, targets)\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "def train_step(state, batch):\n",
        "  grad_fn = jax.value_and_grad(forward_pass, argnums=(0))  # differentiate wrt 0th pos argument.\n",
        "  loss, grads = grad_fn(state.params, state, batch)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state, loss\n",
        "\n",
        "opt = optax.adam(learning_rate=0.0001)\n",
        "state = TrainState.create(apply_fn=model_apply_batch, params=params, tx=opt, key=random_key)"
      ],
      "metadata": {
        "id": "7e9M7_uLZ1VR"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  batch = get_batch()\n",
        "\n",
        "  random_key, random_subkey = jax.random.split(random_key)\n",
        "  dropout_key = jax.random.fold_in(key=random_key, data=state.step)\n",
        "\n",
        "  state, loss = train_step(state, batch)\n",
        "  print(\"loss\", loss, \"epoch\", epoch) if epoch%1==0 else None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFzsWcLnnw0X",
        "outputId": "c2680a33-e96e-4f14-8c23-3ab643fb4e75"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 3.155889 epoch 0\n",
            "loss 2.6199641 epoch 1\n",
            "loss 2.6245441 epoch 2\n",
            "loss 2.5297794 epoch 3\n",
            "loss 2.7282379 epoch 4\n",
            "loss 2.5052311 epoch 5\n",
            "loss 2.3105931 epoch 6\n",
            "loss 2.5190861 epoch 7\n",
            "loss 2.4369555 epoch 8\n",
            "loss 2.616269 epoch 9\n"
          ]
        }
      ]
    }
  ]
}