{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Mapping, Tuple\n",
        "\n",
        "import chex\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jrand\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "import functools\n",
        "\n",
        "def println(*args):\n",
        "  for arg in args:\n",
        "    print(arg)\n"
      ],
      "metadata": {
        "id": "72Nj51EWBerM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "# jax.devices()"
      ],
      "metadata": {
        "id": "jBNxJaDJLWKG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE_COUNT = len(jax.devices())\n",
        "DEVICE_COUNT"
      ],
      "metadata": {
        "id": "sqescrf0Sslj",
        "outputId": "8bb5c485-e6d1-40c9-fa76-38f16e15a38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 96"
      ],
      "metadata": {
        "id": "WaGPnFqLUxFa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset pipline"
      ],
      "metadata": {
        "id": "ukGZuNfiXSkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "def create_dataset():\n",
        "  # Create a TensorFlow data pipeline for the training set\n",
        "  train_dataset = (\n",
        "      tf.data.Dataset\n",
        "      .from_tensor_slices((x_train, y_train))\n",
        "      .repeat()\n",
        "      .shuffle(buffer_size=5000)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "      .as_numpy_iterator())\n",
        "\n",
        "  # Create a TensorFlow data pipeline for the test set.\n",
        "  test_dataset = (\n",
        "      tf.data.Dataset\n",
        "      .from_tensor_slices((x_test, y_test))\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        "      .as_numpy_iterator())\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "def get_batch(dataset):\n",
        "  images, labels = next(dataset)\n",
        "\n",
        "  images, labels = jnp.array(images), jnp.array(labels)\n",
        "  images = jnp.reshape(images, (BATCH_SIZE, -1)) # flatten the images\n",
        "  return images, labels\n",
        "\n",
        "train_dataset, test_dataset = create_dataset()"
      ],
      "metadata": {
        "id": "6SZi0CVi9hbf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test get_batch"
      ],
      "metadata": {
        "id": "COmCti08XaWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_labels = get_batch(train_dataset)\n",
        "test_images.shape, test_labels.shape"
      ],
      "metadata": {
        "id": "7cgyLqLk_bKc",
        "outputId": "f9361368-06ab-4af3-c9bb-6ab15cc5e34b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((96, 784), (96, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image, est_label = test_images[0], test_labels[0]\n",
        "test_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBoE30Yd1x7E",
        "outputId": "db2512a5-7bd4-48e9-ba8e-20c88cf89044"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "rUpckDyi4aKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "\n",
        "  def setup(self):\n",
        "    self._encoder = nn.Sequential([\n",
        "        nn.Dense(128), # 784->128\n",
        "        nn.relu,\n",
        "        nn.Dense(64), # 128->64\n",
        "        nn.relu,\n",
        "        nn.Dense(12), # 64->12\n",
        "        nn.relu,\n",
        "        nn.Dense(3) # 12->3\n",
        "    ])\n",
        "\n",
        "    self._decoder = nn.Sequential([\n",
        "        nn.Dense(12), # 3->12\n",
        "        nn.relu,\n",
        "        nn.Dense(64), # 12->64\n",
        "        nn.relu,\n",
        "        nn.Dense(128), # 64->128\n",
        "        nn.relu,\n",
        "        nn.Dense(784), # 128->784\n",
        "        nn.sigmoid\n",
        "    ])\n",
        "\n",
        "  def __call__(self, x):\n",
        "    encoded = self._encoder(x)\n",
        "    decoded = self._decoder(encoded)\n",
        "    return decoded"
      ],
      "metadata": {
        "id": "3g5X5Bl57EAJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Autoencoder()\n",
        "params = model.init(jrand.PRNGKey(99), jnp.zeros(shape=(1, 784)))[\"params\"]\n",
        "opt = optax.adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "cvSoJNnI9TZT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = create_dataset()\n",
        "images, labels = get_batch(train_dataset)"
      ],
      "metadata": {
        "id": "YPS2Oqv-94GU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recons = model.apply({\"params\": params}, images)"
      ],
      "metadata": {
        "id": "ThsJoM9g-x0m"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = train_state.TrainState.create(apply_fn=model.apply,\n",
        "                                      params=params,\n",
        "                                      tx=opt)"
      ],
      "metadata": {
        "id": "5XtqDqbYLh6V"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_loss(input, recon):\n",
        "  return jnp.mean((input - recon)**2)"
      ],
      "metadata": {
        "id": "_5uiqOzYQHao"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(params, state, batch):\n",
        "  def _compute_loss(params):\n",
        "    inputs, _ = batch\n",
        "    recons = state.apply_fn({\"params\": params}, inputs)\n",
        "    recon_losses = jax.vmap(mse_loss)(inputs, recons)\n",
        "    loss = jnp.mean(recon_losses) # mean loss across batch\n",
        "    return loss\n",
        "\n",
        "  grad_fn = jax.value_and_grad(_compute_loss)\n",
        "  loss, grads = grad_fn(params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state, loss"
      ],
      "metadata": {
        "id": "Xk6x9Q73IBha"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state, loss = train_step(params, state, (images, labels))"
      ],
      "metadata": {
        "id": "ucR5p3c4PsYq"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "steps_per_epoch = len(x_train) // BATCH_SIZE\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"epoch: \", epoch)\n",
        "    train_dataset, _ = create_dataset()\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        batch = get_batch(train_dataset)\n",
        "\n",
        "        params = state.params\n",
        "        state, loss = train_step(params, state, batch)\n",
        "        print(\"loss\", loss) if step%100==0 else None\n",
        ""
      ],
      "metadata": {
        "id": "Fdrtq_XEEgUo",
        "outputId": "56407a00-6f98-4b5b-e468-1325ef49319e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n",
            "loss 0.22952096\n",
            "loss 0.064420894\n",
            "loss 0.06163464\n",
            "loss 0.052448533\n",
            "loss 0.048550844\n",
            "loss 0.045323335\n",
            "loss 0.04582125\n",
            "epoch:  1\n",
            "loss 0.04300247\n",
            "loss 0.04237263\n",
            "loss 0.044522047\n",
            "loss 0.04462269\n",
            "loss 0.039602436\n",
            "loss 0.042121753\n",
            "loss 0.0379778\n",
            "epoch:  2\n",
            "loss 0.038252622\n",
            "loss 0.042860053\n"
          ]
        }
      ]
    }
  ]
}